27,29c27
< #include "SimpleVRaudio.h"
< #include "Win32_DirectXAppUtil.h"
< 
---
> #include "../../OculusRoomTiny_Advanced/Common/Win32_DirectXAppUtil.h"
33,35c31
< #include "Extras\OVR_Math.h"
< #include <memory>
< #include "maxlimits.h"
---
> 
40d35
< 
43c38
< 	ovrSession               Session;
---
>     ovrSession               Session;
45c40
< 	std::vector<ID3D11RenderTargetView*> TexRtv;
---
>     std::vector<ID3D11RenderTargetView*> TexRtv;
47,51c42,46
< 	OculusTexture() :
< 		Session(nullptr),
< 		TextureChain(nullptr)
< 	{
< 	}
---
>     OculusTexture() :
>         Session(nullptr),
>         TextureChain(nullptr)
>     {
>     }
53c48
< 	bool Init(ovrSession session, int sizeW, int sizeH)
---
>     bool Init(ovrSession session, int sizeW, int sizeH)
55c50
< 		Session = session;
---
>         Session = session;
57,71c52,66
< 		ovrTextureSwapChainDesc desc = {};
< 		desc.Type = ovrTexture_2D;
< 		desc.ArraySize = 1;
< 		desc.Format = OVR_FORMAT_R8G8B8A8_UNORM_SRGB;
< 		desc.Width = sizeW;
< 		desc.Height = sizeH;
< 		desc.MipLevels = 1;
< 		desc.SampleCount = 1;
< 		desc.MiscFlags = ovrTextureMisc_DX_Typeless;
< 		desc.BindFlags = ovrTextureBind_DX_RenderTarget;
< 		desc.StaticImage = ovrFalse;
< 
< 		ovrResult result = ovr_CreateTextureSwapChainDX(session, DIRECTX.Device, &desc, &TextureChain);
< 		if (!OVR_SUCCESS(result))
< 			return false;
---
>         ovrTextureSwapChainDesc desc = {};
>         desc.Type = ovrTexture_2D;
>         desc.ArraySize = 1;
>         desc.Format = OVR_FORMAT_R8G8B8A8_UNORM_SRGB;
>         desc.Width = sizeW;
>         desc.Height = sizeH;
>         desc.MipLevels = 1;
>         desc.SampleCount = 1;
>         desc.MiscFlags = ovrTextureMisc_DX_Typeless;
>         desc.BindFlags = ovrTextureBind_DX_RenderTarget;
>         desc.StaticImage = ovrFalse;
> 
>         ovrResult result = ovr_CreateTextureSwapChainDX(session, DIRECTX.Device, &desc, &TextureChain);
>         if (!OVR_SUCCESS(result))
>             return false;
73,74c68,69
< 		int textureCount = 0;
< 		ovr_GetTextureSwapChainLength(Session, TextureChain, &textureCount);
---
>         int textureCount = 0;
>         ovr_GetTextureSwapChainLength(Session, TextureChain, &textureCount);
77,78c72,73
< 			ID3D11Texture2D* tex = nullptr;
< 			ovr_GetTextureSwapChainBufferDX(Session, TextureChain, i, IID_PPV_ARGS(&tex));
---
>             ID3D11Texture2D* tex = nullptr;
>             ovr_GetTextureSwapChainBufferDX(Session, TextureChain, i, IID_PPV_ARGS(&tex));
82c77
< 			ID3D11RenderTargetView* rtv;
---
>             ID3D11RenderTargetView* rtv;
84,85c79,80
< 			TexRtv.push_back(rtv);
< 			tex->Release();
---
>             TexRtv.push_back(rtv);
>             tex->Release();
88,89c83,84
< 		return true;
< 	}
---
>         return true;
>     }
94,96c89,91
< 		{
< 			Release(TexRtv[i]);
< 		}
---
>         {
>             Release(TexRtv[i]);
>         }
98,100c93,95
< 		{
< 			ovr_DestroyTextureSwapChain(Session, TextureChain);
< 		}
---
>         {
>             ovr_DestroyTextureSwapChain(Session, TextureChain);
>         }
103c98
< 	ID3D11RenderTargetView* GetRTV()
---
>     ID3D11RenderTargetView* GetRTV()
105,108c100,103
< 		int index = 0;
< 		ovr_GetTextureSwapChainCurrentIndex(Session, TextureChain, &index);
< 		return TexRtv[index];
< 	}
---
>         int index = 0;
>         ovr_GetTextureSwapChainCurrentIndex(Session, TextureChain, &index);
>         return TexRtv[index];
>     }
110c105
< 	// Commit changes
---
>     // Commit changes
113c108
< 		ovr_CommitTextureSwapChain(Session, TextureChain);
---
>         ovr_CommitTextureSwapChain(Session, TextureChain);
117,127d111
< #  define RETURN_IF_FALSE(x) \
<     { \
<         bool tmp = (x); \
<         if (!tmp) { \
<             ::MessageBoxA(0, #x, "Error", MB_OK); \
<             result = -1; \
<             goto Done; \
<         } \
<     }
< 
< 
132,134c116,118
<     ovrMirrorTexture      mirrorTexture = nullptr;
<     OculusTexture  * pEyeRenderTexture[2] = { nullptr, nullptr };
<     DepthBuffer    * pEyeDepthBuffer[2] = { nullptr, nullptr };
---
> 	ovrMirrorTexture mirrorTexture = nullptr;
> 	OculusTexture  * pEyeRenderTexture[2] = { nullptr, nullptr };
> 	DepthBuffer    * pEyeDepthBuffer[2] = { nullptr, nullptr };
137,140c121,123
< 	ovrMirrorTextureDesc mirrorDesc = {};
< 	bool isVisible = true;
< 	long long frameIndex = 0;
< 
---
>     ovrMirrorTextureDesc mirrorDesc = {};
>     bool isVisible       = true;
>     long long frameIndex = 0;
142,143c125,126
<     ovrSession session;
<     ovrGraphicsLuid luid;
---
> 	ovrSession session;
> 	ovrGraphicsLuid luid;
150,193c133,134
< 	//TAN >>>>>>
< 	//
<     //Initialize the AMD True Audio Next audio engine:
< 	//
<     std::auto_ptr<Audio3D> pAudioVR(new Audio3D());
< 
< 	// define acoustic room properties to match VR room:
<     RoomDefinition roomDef;
<     roomDef.height = 4.0;
<     roomDef.width = 20.0;
<     roomDef.length = 40.0;
<     roomDef.mLeft.damp = DBTODAMP(1.0);
<     roomDef.mRight.damp = DBTODAMP(1.0);
<     roomDef.mFront.damp = DBTODAMP(1.0);
<     roomDef.mBack.damp = DBTODAMP(1.0);
<     roomDef.mTop.damp = DBTODAMP(1.0);
<     roomDef.mBottom.damp = DBTODAMP(1.0);
< 
< 	// Edit inFiles to change sound associated sources in the room:
<     char *inFiles[MAX_SOURCES];
<     inFiles[0] = "stream1.wav";    // Music Box
<     inFiles[1] = "stream2.wav";	   // Thumper
<     inFiles[2] = "stream3.wav";	   // Table Radio
< 
< 	// Initialize the audio engine for 3 streams, 64k convolution, 4k buffers:
<     RETURN_IF_FALSE(pAudioVR->init(NULL, roomDef, 3, inFiles, 65536, 4096) == 0);
< 	// Set transform to convert VR room coordinates to audio room sim:
< 	pAudioVR->setWorldToRoomCoordTransform(roomDef.width / 2.0f, 0.0, roomDef.length / 2.0f, 0.0, 180.0, false);
< 
< 	// set initial source and head positions:
<     RETURN_IF_FALSE(pAudioVR->updateSourcePosition(0, 0.0, 2.0, 5.0) == 0);
< 	RETURN_IF_FALSE(pAudioVR->updateSourcePosition(0, 0.0, 2.0, 5.0) == 0);
< 	RETURN_IF_FALSE(pAudioVR->updateSourcePosition(0, 0.0, 2.0, 5.0) == 0);
< 	RETURN_IF_FALSE(pAudioVR->updateHeadPosition(0.0, 2.0, 0.0, 0.0, 0.0, 0.0) == 0);
< 
< 	//start audio engine
<     RETURN_IF_FALSE(pAudioVR->Run() == 0);
< 	//
< 	// Done initializing AMD True Audio Next audio engine.
< 	//
< 	// TAN <<<<<<<
< 
<     // Setup Device and Graphics
<     // Note: the mirror window can be any size, for this sample we use 1/2 the HMD resolution
---
> 	// Setup Device and Graphics
> 	// Note: the mirror window can be any size, for this sample we use 1/2 the HMD resolution
197,209c138,142
< //    // Start the sensor which informs of the Rift's pose and motion
< //    result = ovr_ConfigureTracking(HMD, ovrTrackingCap_Orientation | ovrTrackingCap_MagYawCorrection | ovrTrackingCap_Position, 0);
< //    if (!OVR_SUCCESS(result))
< //    {
< //        if (retryCreate) goto Done;
< //        VALIDATE(OVR_SUCCESS(result), "Failed to configure tracking.");
< //    }
< 
<     // Make the eye render buffers (caution if actual size < requested due to HW limits). 
<     ovrRecti         eyeRenderViewport[2];
<     
<     for (int eye = 0; eye < 2; ++eye)
<     {
---
> 	// Make the eye render buffers (caution if actual size < requested due to HW limits). 
> 	ovrRecti         eyeRenderViewport[2];
> 
> 	for (int eye = 0; eye < 2; ++eye)
> 	{
212,216c145,149
< 		if (!pEyeRenderTexture[eye]->Init(session, idealSize.w, idealSize.h))
< 		{
< 			if (retryCreate) goto Done;
< 			VALIDATE(false, "Failed to create eye texture.");
< 		}
---
>         if (!pEyeRenderTexture[eye]->Init(session, idealSize.w, idealSize.h))
>         {
>             if (retryCreate) goto Done;
> 	        VALIDATE(false, "Failed to create eye texture.");
>         }
221,236c154,158
< 		if (!pEyeRenderTexture[eye]->TextureChain)
< 		{
< 			if (retryCreate) goto Done;
< 			VALIDATE(false, "Failed to create texture.");
< 		}
<     }
< 
<     // Create a mirror to see on the monitor.
< 	mirrorDesc.Format = OVR_FORMAT_R8G8B8A8_UNORM_SRGB;
< 	mirrorDesc.Width = DIRECTX.WinSizeW;
< 	mirrorDesc.Height = DIRECTX.WinSizeH;
< 	result = ovr_CreateMirrorTextureDX(session, DIRECTX.Device, &mirrorDesc, &mirrorTexture);
< 	if (!OVR_SUCCESS(result))
< 	{
< 		if (retryCreate) goto Done;
< 		VALIDATE(false, "Failed to create mirror texture.");
---
>         if (!pEyeRenderTexture[eye]->TextureChain)
>         {
>             if (retryCreate) goto Done;
>             VALIDATE(false, "Failed to create texture.");
>         }
239,251c161,166
<     // Create the room model
<     roomScene = new Scene(false);
< 
<     mainCam = new Camera(&XMVectorSet(0.0f, 0.0f, 0.0f, 0), &XMQuaternionIdentity());
< 
< 	// FloorLevel will give tracking poses where the floor height is 0
< 	ovr_SetTrackingOriginType(session, ovrTrackingOrigin_FloorLevel);
< 
<     // Setup VR components, filling out description
< 
< 
<     // Main loop
<     while (DIRECTX.HandleMessages())
---
> 	// Create a mirror to see on the monitor.
>     mirrorDesc.Format = OVR_FORMAT_R8G8B8A8_UNORM_SRGB;
>     mirrorDesc.Width = DIRECTX.WinSizeW;
>     mirrorDesc.Height = DIRECTX.WinSizeH;
>     result = ovr_CreateMirrorTextureDX(session, DIRECTX.Device, &mirrorDesc, &mirrorTexture);
>     if (!OVR_SUCCESS(result))
253,270c168,170
<         XMVECTOR forward = XMVector3Rotate(XMVectorSet(0, 0, -0.05f, 0), mainCam->Rot);
<         XMVECTOR right   = XMVector3Rotate(XMVectorSet(0.05f, 0, 0, 0),  mainCam->Rot);
<         if (DIRECTX.Key['W'] || DIRECTX.Key[VK_UP])	  mainCam->Pos = XMVectorAdd(mainCam->Pos, forward);
<         if (DIRECTX.Key['S'] || DIRECTX.Key[VK_DOWN]) mainCam->Pos = XMVectorSubtract(mainCam->Pos, forward);
<         if (DIRECTX.Key['D'])                         mainCam->Pos = XMVectorAdd(mainCam->Pos, right);
<         if (DIRECTX.Key['A'])                         mainCam->Pos = XMVectorSubtract(mainCam->Pos, right);
<         static float Yaw = 0;
<         if (DIRECTX.Key[VK_LEFT])  mainCam->Rot = XMQuaternionRotationRollPitchYaw(0, Yaw += 0.02f, 0);
<         if (DIRECTX.Key[VK_RIGHT]) mainCam->Rot = XMQuaternionRotationRollPitchYaw(0, Yaw -= 0.02f, 0);
< 
<         // Animate the cube
<         static float cubeClock = 0; 
< 
<         roomScene->Models[0]->Pos = XMFLOAT3(9 * sin(cubeClock), 3, 9 * cos(cubeClock += 0.015f)); //hack XMFLOAT3(0.0,2.0,0.0);//
< 
< 		ovrEyeRenderDesc eyeRenderDesc[2];
< 		eyeRenderDesc[0] = ovr_GetRenderDesc(session, ovrEye_Left, hmdDesc.DefaultEyeFov[0]);
< 		eyeRenderDesc[1] = ovr_GetRenderDesc(session, ovrEye_Right, hmdDesc.DefaultEyeFov[1]);
---
>         if (retryCreate) goto Done;
>         VALIDATE(false, "Failed to create mirror texture.");
>     }
272,278c172,173
<         // TAN >>>> 
< 		// Update cube's position in 3D Audio library.
<         {
<             float Sx, Sy, Sz;
<             Sx = roomScene->Models[0]->Pos.x;
<             Sy = roomScene->Models[0]->Pos.y;
<             Sz = -roomScene->Models[0]->Pos.z;
---
> 	// Create the room model
>     roomScene = new Scene(false);
280,281c175,176
<             pAudioVR->updateSourcePosition(0, Sx, Sy, Sz);
<         }
---
> 	// Create camera
>     mainCam = new Camera(&XMVectorSet(0.0f, 0.0f, 5.0f, 0), &XMQuaternionIdentity());
283,303c178,179
<         // Animate Hammer
<         {
<             float x, y, z;
<             x = -5.0;
<             y = 0.0;
<             z = 10.0;
< 
<             float dy = 0.0;
<             float dt = pAudioVR->getCurrentPosition(1) / 48000.0f;
< 
<             dt = dt - 5.0f * floorf(dt / 5.0f);
< 
<             if (dt < .638f) {
<                 dy = 3.0f - 0.5f * 9.8f * dt*dt;
<             }
<             else if (dt < 1.0f) {
<                 dy = 0.0f;
<             }
<             else {
<                 dy = (dt - 1.0f) * 3.0f / 4.0f;
<             }
---
>     // FloorLevel will give tracking poses where the floor height is 0
>     ovr_SetTrackingOriginType(session, ovrTrackingOrigin_FloorLevel);
305,322c181,201
<             roomScene->Models[1]->Pos = XMFLOAT3(x, 1.0f + y + dy, z);  //hammer
<             roomScene->Models[2]->Pos = XMFLOAT3(-5.0f, 0.0f, z);       //anvil
<         }
< 
< 		// TAN >>>> 
< 		// Update hammer's position in 3D Audio library.
<         RETURN_IF_FALSE(pAudioVR->updateSourcePosition(1, roomScene->Models[1]->Pos.x,
<                                                        roomScene->Models[1]->Pos.y,
<                                                        -roomScene->Models[1]->Pos.z) == 0);
< 
<         // Place radio
<         roomScene->Models[3]->Pos = XMFLOAT3(-1.8f, .8f, .06f); //radio
< 
< 		// TAN >>>> 
< 		// Update radio's position in 3D Audio library.
<         RETURN_IF_FALSE(pAudioVR->updateSourcePosition(2, roomScene->Models[3]->Pos.x,
<                                                        roomScene->Models[3]->Pos.y,
<                                                        -roomScene->Models[3]->Pos.z) == 0);
---
> 	// Main loop
> 	while (DIRECTX.HandleMessages())
> 	{
> 		XMVECTOR forward = XMVector3Rotate(XMVectorSet(0, 0, -0.05f, 0), mainCam->Rot);
> 		XMVECTOR right   = XMVector3Rotate(XMVectorSet(0.05f, 0, 0, 0),  mainCam->Rot);
> 		if (DIRECTX.Key['W'] || DIRECTX.Key[VK_UP])	  mainCam->Pos = XMVectorAdd(mainCam->Pos, forward);
> 		if (DIRECTX.Key['S'] || DIRECTX.Key[VK_DOWN]) mainCam->Pos = XMVectorSubtract(mainCam->Pos, forward);
> 		if (DIRECTX.Key['D'])                         mainCam->Pos = XMVectorAdd(mainCam->Pos, right);
> 		if (DIRECTX.Key['A'])                         mainCam->Pos = XMVectorSubtract(mainCam->Pos, right);
> 		static float Yaw = 0;
> 		if (DIRECTX.Key[VK_LEFT])  mainCam->Rot = XMQuaternionRotationRollPitchYaw(0, Yaw += 0.02f, 0);
> 		if (DIRECTX.Key[VK_RIGHT]) mainCam->Rot = XMQuaternionRotationRollPitchYaw(0, Yaw -= 0.02f, 0);
> 
> 		// Animate the cube
> 		static float cubeClock = 0;
> 		roomScene->Models[0]->Pos = XMFLOAT3(9 * sin(cubeClock), 3, 9 * cos(cubeClock += 0.015f));
> 
> 	    // Call ovr_GetRenderDesc each frame to get the ovrEyeRenderDesc, as the returned values (e.g. HmdToEyeOffset) may change at runtime.
> 	    ovrEyeRenderDesc eyeRenderDesc[2];
> 	    eyeRenderDesc[0] = ovr_GetRenderDesc(session, ovrEye_Left, hmdDesc.DefaultEyeFov[0]);
> 	    eyeRenderDesc[1] = ovr_GetRenderDesc(session, ovrEye_Right, hmdDesc.DefaultEyeFov[1]);
324,325c203,204
<         // Get both eye poses simultaneously, with IPD offset already included. 
<         ovrPosef         EyeRenderPose[2];
---
> 		// Get both eye poses simultaneously, with IPD offset already included. 
> 		ovrPosef         EyeRenderPose[2];
327,331c206
<                                                    eyeRenderDesc[1].HmdToEyeOffset };
<         
< 
< 		double sensorSampleTime;    // sensorSampleTime is fed into the layer later
< 		ovr_GetEyePoses(session, frameIndex, ovrTrue, HmdToEyeOffset, EyeRenderPose, &sensorSampleTime);
---
> 			                                   eyeRenderDesc[1].HmdToEyeOffset };
332a208,209
>         double sensorSampleTime;    // sensorSampleTime is fed into the layer later
>         ovr_GetEyePoses(session, frameIndex, ovrTrue, HmdToEyeOffset, EyeRenderPose, &sensorSampleTime);
334,351c211
< 		// TAN >>>> 
< 		// 3D Audio - update head's position.
<         {
< 			const float headX = mainCam->Pos.m128_f32[0] +
< 				(EyeRenderPose[0].Position.x + EyeRenderPose[1].Position.x) / 2;
<             const float headY = mainCam->Pos.m128_f32[1] +
<                                 (EyeRenderPose[0].Position.y + EyeRenderPose[1].Position.y) / 2;
< 			const float headZ =  - mainCam->Pos.m128_f32[2] +
< 				(EyeRenderPose[0].Position.z + EyeRenderPose[1].Position.z) / 2;
< 
<             float hYaw, hPitch, hRoll;
<             OVR::Posef pose = EyeRenderPose[0];
<             pose.Rotation.GetEulerAngles<OVR::Axis_Y, OVR::Axis_X, OVR::Axis_Z>(&hYaw, &hPitch, &hRoll);
< 
< 			// Note: audio engine head orientation angles need to be in degrees, so multiply by 180/PI:
<             RETURN_IF_FALSE(pAudioVR->updateHeadPosition(headX, headY, headZ, (hYaw + Yaw)*180.0 / PI, hPitch*180.0 / PI, hRoll*180.0 / PI) == 0);
<         }
< 
---
> 		// Render Scene to Eye Buffers
355,380c215,240
<             {
< 				// Clear and set up rendertarget
< 				DIRECTX.SetAndClearRenderTarget(pEyeRenderTexture[eye]->GetRTV(), pEyeDepthBuffer[eye]);
< 				DIRECTX.SetViewport((float)eyeRenderViewport[eye].Pos.x, (float)eyeRenderViewport[eye].Pos.y,
< 					(float)eyeRenderViewport[eye].Size.w, (float)eyeRenderViewport[eye].Size.h);
< 
< 				//Get the pose information in XM format
< 				XMVECTOR eyeQuat = XMVectorSet(EyeRenderPose[eye].Orientation.x, EyeRenderPose[eye].Orientation.y,
< 					EyeRenderPose[eye].Orientation.z, EyeRenderPose[eye].Orientation.w);
< 				XMVECTOR eyePos = XMVectorSet(EyeRenderPose[eye].Position.x, EyeRenderPose[eye].Position.y, EyeRenderPose[eye].Position.z, 0);
< 
< 				// Get view and projection matrices for the Rift camera
< 				XMVECTOR CombinedPos = XMVectorAdd(mainCam->Pos, XMVector3Rotate(eyePos, mainCam->Rot));
< 				Camera finalCam(&CombinedPos, &(XMQuaternionMultiply(eyeQuat, mainCam->Rot)));
< 				XMMATRIX view = finalCam.GetViewMatrix();
< 				ovrMatrix4f p = ovrMatrix4f_Projection(eyeRenderDesc[eye].Fov, 0.2f, 1000.0f, ovrProjection_None);
< 				XMMATRIX proj = XMMatrixSet(p.M[0][0], p.M[1][0], p.M[2][0], p.M[3][0],
< 					p.M[0][1], p.M[1][1], p.M[2][1], p.M[3][1],
< 					p.M[0][2], p.M[1][2], p.M[2][2], p.M[3][2],
< 					p.M[0][3], p.M[1][3], p.M[2][3], p.M[3][3]);
< 				XMMATRIX prod = XMMatrixMultiply(view, proj);
< 				roomScene->Render(&prod, 1, 1, 1, 1, true);
< 
< 				// Commit rendering to the swap chain
< 				pEyeRenderTexture[eye]->Commit();
<             }
---
> 		    {
> 			    // Clear and set up rendertarget
> 			    DIRECTX.SetAndClearRenderTarget(pEyeRenderTexture[eye]->GetRTV(), pEyeDepthBuffer[eye]);
> 			    DIRECTX.SetViewport((float)eyeRenderViewport[eye].Pos.x, (float)eyeRenderViewport[eye].Pos.y,
> 				                    (float)eyeRenderViewport[eye].Size.w, (float)eyeRenderViewport[eye].Size.h);
> 
> 			    //Get the pose information in XM format
> 			    XMVECTOR eyeQuat = XMVectorSet(EyeRenderPose[eye].Orientation.x, EyeRenderPose[eye].Orientation.y,
> 				                               EyeRenderPose[eye].Orientation.z, EyeRenderPose[eye].Orientation.w);
> 			    XMVECTOR eyePos = XMVectorSet(EyeRenderPose[eye].Position.x, EyeRenderPose[eye].Position.y, EyeRenderPose[eye].Position.z, 0);
> 
> 			    // Get view and projection matrices for the Rift camera
> 			    XMVECTOR CombinedPos = XMVectorAdd(mainCam->Pos, XMVector3Rotate(eyePos, mainCam->Rot));
> 			    Camera finalCam(&CombinedPos, &(XMQuaternionMultiply(eyeQuat,mainCam->Rot)));
> 			    XMMATRIX view = finalCam.GetViewMatrix();
>                 ovrMatrix4f p = ovrMatrix4f_Projection(eyeRenderDesc[eye].Fov, 0.2f, 1000.0f, ovrProjection_None);
> 			    XMMATRIX proj = XMMatrixSet(p.M[0][0], p.M[1][0], p.M[2][0], p.M[3][0],
> 				                            p.M[0][1], p.M[1][1], p.M[2][1], p.M[3][1],
> 				                            p.M[0][2], p.M[1][2], p.M[2][2], p.M[3][2],
> 				                            p.M[0][3], p.M[1][3], p.M[2][3], p.M[3][3]);
> 			    XMMATRIX prod = XMMatrixMultiply(view, proj);
> 			    roomScene->Render(&prod, 1, 1, 1, 1, true);
> 
>                 // Commit rendering to the swap chain
>                 pEyeRenderTexture[eye]->Commit();
> 		    }
383c243
<         // Initialize our single full screen Fov layer.
---
> 		// Initialize our single full screen Fov layer.
385,386c245,246
<         ld.Header.Type  = ovrLayerType_EyeFov;
<         ld.Header.Flags = 0;
---
> 		ld.Header.Type = ovrLayerType_EyeFov;
> 		ld.Header.Flags = 0;
388,389c248,249
<         for (int eye = 0; eye < 2; ++eye)
<         {
---
> 		for (int eye = 0; eye < 2; ++eye)
> 		{
394,395c254,255
< 			ld.SensorSampleTime = sensorSampleTime;
<         }
---
>             ld.SensorSampleTime = sensorSampleTime;
> 		}
398c258
<         result = ovr_SubmitFrame(session, 0, nullptr, &layers, 1);
---
>         result = ovr_SubmitFrame(session, frameIndex, nullptr, &layers, 1);
405,417c265,270
< 		ovrSessionStatus sessionStatus;
< 		ovr_GetSessionStatus(session, &sessionStatus);
< 		if (sessionStatus.ShouldQuit)
< 			goto Done;
< 		if (sessionStatus.ShouldRecenter)
< 			ovr_RecenterTrackingOrigin(session);
< 
< 		// Render mirror
< 		ID3D11Texture2D* tex = nullptr;
< 		ovr_GetMirrorTextureBufferDX(session, mirrorTexture, IID_PPV_ARGS(&tex));
< 		DIRECTX.Context->CopyResource(DIRECTX.BackBuffer, tex);
< 		tex->Release();
< 		DIRECTX.SwapChain->Present(0, 0);
---
>         ovrSessionStatus sessionStatus;
>         ovr_GetSessionStatus(session, &sessionStatus);
>         if (sessionStatus.ShouldQuit)
>             goto Done;
>         if (sessionStatus.ShouldRecenter)
>             ovr_RecenterTrackingOrigin(session);
419,420c272,277
< 		frameIndex++;
<     }
---
>         // Render mirror
>         ID3D11Texture2D* tex = nullptr;
>         ovr_GetMirrorTextureBufferDX(session, mirrorTexture, IID_PPV_ARGS(&tex));
>         DIRECTX.Context->CopyResource(DIRECTX.BackBuffer, tex);
>         tex->Release();
>         DIRECTX.SwapChain->Present(0, 0);
422c279,282
<     // Release resources
---
>         frameIndex++;
> 	}
> 
> 	// Release resources
426c286,287
<     if (mirrorTexture) ovr_DestroyMirrorTexture(session, mirrorTexture);
---
> 	if (mirrorTexture)
>         ovr_DestroyMirrorTexture(session, mirrorTexture);
429c290
<         delete pEyeRenderTexture[eye];
---
> 	    delete pEyeRenderTexture[eye];
432,435c293,294
<     DIRECTX.ReleaseDevice();
<     ovr_Destroy(session);
< 
<     pAudioVR->Stop();
---
> 	DIRECTX.ReleaseDevice();
> 	ovr_Destroy(session);
444,447c303,306
<     // Initializes LibOVR, and the Rift
<     ovrResult result = ovr_Initialize(nullptr);
<     VALIDATE(OVR_SUCCESS(result), "Failed to initialize libOVR.");
< 	                                                                                                
---
> 	// Initializes LibOVR, and the Rift
> 	ovrResult result = ovr_Initialize(nullptr);
> 	VALIDATE(OVR_SUCCESS(result), "Failed to initialize libOVR.");
> 
450d308
< 	CoInitializeEx(NULL,COINIT_MULTITHREADED);
453,454c311,312
<     ovr_Shutdown();
<     return(0);
---
> 	ovr_Shutdown();
> 	return(0);
